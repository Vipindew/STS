{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0687f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#import file\n",
    "\n",
    "File = pd.read_csv(\"Text_Similarity_Dataset.csv\") \n",
    "T1=File['text1']\n",
    "T2=File['text2']\n",
    "Id=File['Unique_ID']\n",
    "\n",
    "Token1=[]\n",
    "Token2=[]\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "for i in range(len(T1)):\n",
    "    # Sentence conveerted into lower case \n",
    "    \n",
    "    p1 = T1[i].lower()\n",
    "    p2 = T2[i].lower()\n",
    "    \n",
    "    # Remove non letter and white space characters\n",
    "    \n",
    "    p1 = re.sub('[^a-zA-Z]', ' ', p1)\n",
    "    p2 = re.sub('[^a-zA-Z]', ' ', p2)\n",
    "    p1 = re.sub(r'\\s+', ' ', p1)\n",
    "    p2 = re.sub(r'\\s+', ' ', p2)\n",
    "\n",
    "    # Sentence tokenization\n",
    "    \n",
    "    all1 = nltk.sent_tokenize(p1)\n",
    "    all2 = nltk.sent_tokenize(p2)\n",
    "\n",
    "    all_words1 = [nltk.word_tokenize(sent) for sent in all1]\n",
    "    all_words2 = [nltk.word_tokenize(sent) for sent in all2]\n",
    "    \n",
    "    # Stop words tokes are removed \n",
    "    \n",
    "    for y in range(len(all_words1)):\n",
    "        all_words1[y] = [w for w in all_words1[y] if w not in stopwords.words('english')]\n",
    "    for y in range(len(all_words2)):\n",
    "        all_words2[y] = [w for w in all_words2[y] if w not in stopwords.words('english')]\n",
    "    \n",
    "    Token1+=all_words1\n",
    "    Token2+=all_words2\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a1185008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corpus is generated from sentences\n",
    "nCorpus=[]\n",
    "\n",
    "for i in range(len(Token1)):\n",
    "    nCorpus.append(Token1[i])\n",
    "    nCorpus.append(Token2[i])\n",
    "\n",
    "# Corpus fed into Fastext with default parameters and min_count=1\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(nCorpus, min_count=1)\n",
    "\n",
    "# Return a dictionary with unique words and count of words\n",
    "def counter(slist):\n",
    "    dict={}\n",
    "    for y in slist:\n",
    "        if y not in dict.keys():\n",
    "            dict[y]=1\n",
    "        else:\n",
    "            dict[y]+=1\n",
    "    return dict\n",
    "\n",
    "# Calculates mean of a given dictionary by converting the keys into vectors using fasttext model and taking sum.\n",
    "import numpy as np\n",
    "def centroid(dict,len):\n",
    "    sum = np.zeros(100)\n",
    "    for y in dict.keys():\n",
    "        sum+=(dict[y]*model.wv[y])\n",
    "    return(sum/len)\n",
    "\n",
    "# Sentences are converted into dictionary with word count\n",
    "Tokendict1=[]\n",
    "Tokendict2=[]\n",
    "for i in range(len(Token1)):\n",
    "    Tokendict1.append(counter(Token1[i]))\n",
    "    Tokendict2.append(counter(Token2[i]))\n",
    "\n",
    "# cosine between two sence pairs are stored\n",
    "from scipy import spatial\n",
    "\n",
    "cosine=[]\n",
    "for i in range(len(Token1)):\n",
    "    cosine.append(1 - spatial.distance.cosine(centroid(Tokendict1[i],len(Token1[i])), centroid(Tokendict2[i],len(Token2[i]))))\n",
    "\n",
    "#cosine_similarity_score.csv file is generated\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Unique_ID': Id,\n",
    "        'Similarity_Score': cosine\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns= ['Unique_ID', 'Similarity_Score'])\n",
    "\n",
    "df.to_csv ('cosine_similarity_score.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ff580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
